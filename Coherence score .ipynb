{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe376aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation, PCA, NMF\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf999eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      professor_name                                 school_name  \\\n",
      "0     Leslie  Looney  University Of Illinois at Urbana-Champaign   \n",
      "1     Leslie  Looney  University Of Illinois at Urbana-Champaign   \n",
      "2     Leslie  Looney  University Of Illinois at Urbana-Champaign   \n",
      "3     Leslie  Looney  University Of Illinois at Urbana-Champaign   \n",
      "4     Leslie  Looney  University Of Illinois at Urbana-Champaign   \n",
      "...              ...                                         ...   \n",
      "9995    Jamie  Mills                       University of Alabama   \n",
      "9996    Jamie  Mills                       University of Alabama   \n",
      "9997    Jamie  Mills                       University of Alabama   \n",
      "9998    Jamie  Mills                       University of Alabama   \n",
      "9999    Jamie  Mills                       University of Alabama   \n",
      "\n",
      "           department_name                    local_name state_name  \\\n",
      "0     Astronomy department   Champaign\\xe2\\x80\\x93Urbana         IL   \n",
      "1     Astronomy department   Champaign\\xe2\\x80\\x93Urbana         IL   \n",
      "2     Astronomy department   Champaign\\xe2\\x80\\x93Urbana         IL   \n",
      "3     Astronomy department   Champaign\\xe2\\x80\\x93Urbana         IL   \n",
      "4     Astronomy department   Champaign\\xe2\\x80\\x93Urbana         IL   \n",
      "...                    ...                           ...        ...   \n",
      "9995  Education department                    Tuscaloosa         AL   \n",
      "9996  Education department                    Tuscaloosa         AL   \n",
      "9997  Education department                    Tuscaloosa         AL   \n",
      "9998  Education department                    Tuscaloosa         AL   \n",
      "9999  Education department                    Tuscaloosa         AL   \n",
      "\n",
      "      year_since_first_review  star_rating take_again  diff_index  \\\n",
      "0                        11.0          4.7        NaN         2.0   \n",
      "1                        11.0          4.7        NaN         2.0   \n",
      "2                        11.0          4.7        NaN         2.0   \n",
      "3                        11.0          4.7        NaN         2.0   \n",
      "4                        11.0          4.7        NaN         2.0   \n",
      "...                       ...          ...        ...         ...   \n",
      "9995                     15.0          1.6        17%         4.0   \n",
      "9996                     15.0          1.6        17%         4.0   \n",
      "9997                     15.0          1.6        17%         4.0   \n",
      "9998                     15.0          1.6        17%         4.0   \n",
      "9999                     15.0          1.6        17%         4.0   \n",
      "\n",
      "                                          tag_professor  ...  \\\n",
      "0     Hilarious (2)  GROUP PROJECTS (2)  Gives good ...  ...   \n",
      "1     Hilarious (2)  GROUP PROJECTS (2)  Gives good ...  ...   \n",
      "2     Hilarious (2)  GROUP PROJECTS (2)  Gives good ...  ...   \n",
      "3     Hilarious (2)  GROUP PROJECTS (2)  Gives good ...  ...   \n",
      "4     Hilarious (2)  GROUP PROJECTS (2)  Gives good ...  ...   \n",
      "...                                                 ...  ...   \n",
      "9995  LOTS OF HOMEWORK (3)  LECTURE HEAVY (2)  TEST ...  ...   \n",
      "9996  LOTS OF HOMEWORK (3)  LECTURE HEAVY (2)  TEST ...  ...   \n",
      "9997  LOTS OF HOMEWORK (3)  LECTURE HEAVY (2)  TEST ...  ...   \n",
      "9998  LOTS OF HOMEWORK (3)  LECTURE HEAVY (2)  TEST ...  ...   \n",
      "9999  LOTS OF HOMEWORK (3)  LECTURE HEAVY (2)  TEST ...  ...   \n",
      "\n",
      "      lots_of_homework accessible_outside_class lecture_heavy extra_credit  \\\n",
      "0                    0                        0             0            0   \n",
      "1                    0                        0             0            0   \n",
      "2                    0                        0             0            0   \n",
      "3                    0                        0             0            0   \n",
      "4                    0                        0             0            0   \n",
      "...                ...                      ...           ...          ...   \n",
      "9995                 1                        0             1            0   \n",
      "9996                 1                        0             1            0   \n",
      "9997                 1                        0             1            0   \n",
      "9998                 1                        0             1            0   \n",
      "9999                 1                        0             1            0   \n",
      "\n",
      "      graded_by_few_things  group_projects test_heavy so_many_papers  \\\n",
      "0                        0               1          0              0   \n",
      "1                        0               1          0              0   \n",
      "2                        0               1          0              0   \n",
      "3                        0               1          0              0   \n",
      "4                        0               1          0              0   \n",
      "...                    ...             ...        ...            ...   \n",
      "9995                     0               0          1              0   \n",
      "9996                     0               0          1              0   \n",
      "9997                     0               0          1              0   \n",
      "9998                     0               0          1              0   \n",
      "9999                     0               0          1              0   \n",
      "\n",
      "     beware_of_pop_quizzes IsCourseOnline  \n",
      "0                        0              0  \n",
      "1                        0              0  \n",
      "2                        0              0  \n",
      "3                        0              0  \n",
      "4                        0              0  \n",
      "...                    ...            ...  \n",
      "9995                     0              0  \n",
      "9996                     0              1  \n",
      "9997                     0              1  \n",
      "9998                     0              0  \n",
      "9999                     0              0  \n",
      "\n",
      "[10000 rows x 51 columns]\n"
     ]
    }
   ],
   "source": [
    "complete_dataset = pd.read_csv('complete_dataset.csv')\n",
    "df = complete_dataset.head(10000)\n",
    "print(df)\n",
    "#comments = comments.head(10000) #first 3000 comments\n",
    "#print(comments)\n",
    "#type(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3108e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d27f55e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'comments' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-8d7e931c0603>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcomments_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomments\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcomments_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdoc\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m''\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcomments_list\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomments_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#print(comments_list)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'comments' is not defined"
     ]
    }
   ],
   "source": [
    "comments_list = comments.tolist()\n",
    "comments_list = [doc if isinstance(doc, str) else '' for doc in comments_list]\n",
    "type(comments_list)\n",
    "#print(comments_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8799d525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 500)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(max_features=500, stop_words='english') #max_df=0.5, min_df=5\n",
    "bow_model = vectorizer.fit_transform(comments_list)\n",
    "#print(bow_model)\n",
    "#type(bow_model)\n",
    "#print(bow_model.shape)\n",
    "arr = bow_model.toarray()\n",
    "print(arr.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb669ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      hard  twoinone  gened  knockout  content  stimulating  unlike  actually  \\\n",
      "0        1         1      1         1        1            1       1         1   \n",
      "1        0         0      0         0        0            0       0         0   \n",
      "2        0         0      0         0        0            0       0         0   \n",
      "3        0         0      0         0        1            0       0         0   \n",
      "4        0         0      0         0        0            0       0         0   \n",
      "...    ...       ...    ...       ...      ...          ...     ...       ...   \n",
      "9995     1         0      0         0        0            0       0         0   \n",
      "9996     0         0      0         0        0            0       0         0   \n",
      "9997     1         0      0         0        0            0       0         0   \n",
      "9998     0         0      0         0        0            0       0         0   \n",
      "9999     0         0      0         0        0            0       0         0   \n",
      "\n",
      "      participate  pas  ...  quixote  instrucotr  softie  promoted  \\\n",
      "0               1    1  ...        0           0       0         0   \n",
      "1               0    0  ...        0           0       0         0   \n",
      "2               0    0  ...        0           0       0         0   \n",
      "3               0    0  ...        0           0       0         0   \n",
      "4               0    0  ...        0           0       0         0   \n",
      "...           ...  ...  ...      ...         ...     ...       ...   \n",
      "9995            0    0  ...        0           0       0         0   \n",
      "9996            0    0  ...        0           0       0         0   \n",
      "9997            0    0  ...        0           0       0         0   \n",
      "9998            0    0  ...        0           0       0         0   \n",
      "9999            0    0  ...        0           0       0         0   \n",
      "\n",
      "      bordenlineestoteric  luis  lemos  trickster  borrowed  rewatch  \n",
      "0                       0     0      0          0         0        0  \n",
      "1                       0     0      0          0         0        0  \n",
      "2                       0     0      0          0         0        0  \n",
      "3                       0     0      0          0         0        0  \n",
      "4                       0     0      0          0         0        0  \n",
      "...                   ...   ...    ...        ...       ...      ...  \n",
      "9995                    0     0      0          0         0        0  \n",
      "9996                    0     0      0          0         0        0  \n",
      "9997                    0     0      0          0         0        0  \n",
      "9998                    0     0      0          0         0        0  \n",
      "9999                    0     0      0          0         0        0  \n",
      "\n",
      "[10000 rows x 11029 columns]\n",
      "Index(['hard', 'twoinone', 'gened', 'knockout', 'content', 'stimulating',\n",
      "       'unlike', 'actually', 'participate', 'pas',\n",
      "       ...\n",
      "       'quixote', 'instrucotr', 'softie', 'promoted', 'bordenlineestoteric',\n",
      "       'luis', 'lemos', 'trickster', 'borrowed', 'rewatch'],\n",
      "      dtype='object', length=11029)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('bagOfWords.csv_1000')\n",
    "print(data)\n",
    "X = data.values\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33ce7429",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = LatentDirichletAllocation(n_components = 5, random_state = 42)\n",
    "lda_topics = lda_model.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d49b353c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1678.9234897595188"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.perplexity(X, sub_sampling=False) # perplexity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d17c760e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1148364.7043141893"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.score(X, y=None)   #log-likelihood\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7677ec80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.404819080541836\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "import gensim.corpora as corpora\n",
    "\n",
    "def get_Cv(model, df_columnm):\n",
    "  topics = model.components_\n",
    "\n",
    "  n_top_words = 20\n",
    "  texts = [[word for word in doc.split()] for doc in df_columnm]\n",
    "\n",
    "  # create the dictionary\n",
    "  dictionary = corpora.Dictionary(texts)\n",
    "  # Create a gensim dictionary from the word count matrix\n",
    "\n",
    "  # Create a gensim corpus from the word count matrix\n",
    "  corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "  feature_names = [dictionary[i] for i in range(len(dictionary))]\n",
    "\n",
    "  # Get the top words for each topic from the components_ attribute\n",
    "  top_words = []\n",
    "  for topic in topics:\n",
    "      top_words.append([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "\n",
    "  coherence_model = CoherenceModel(topics=top_words, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "  coherence = coherence_model.get_coherence()\n",
    "  return coherence\n",
    "\n",
    "cv = get_Cv(lda_model, comments_list)\n",
    "print(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0773105e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0271003  0.00427954 0.0015019  0.02733235 0.06863748]\n",
      " [0.01871047 0.00733748 0.02268759 0.02113161 0.07358645]\n",
      " [0.01629305 0.         0.0497529  0.02614877 0.00458157]\n",
      " ...\n",
      " [0.04871682 0.0871678  0.00013674 0.08731778 0.07139845]\n",
      " [0.03879975 0.02877551 0.01816265 0.03402191 0.        ]\n",
      " [0.01438429 0.00354968 0.         0.05478452 0.00695024]]\n"
     ]
    }
   ],
   "source": [
    "nmf_model = NMF(n_components=5, init='random', random_state=42, max_iter=500000)\n",
    "W = nmf_model.fit(X)\n",
    "H = nmf_model.components_\n",
    "DTM = nmf_model.fit_transform(X)\n",
    "print(DTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ee99c70",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NMF' object has no attribute 'perplexity'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-4bb56ba8ff89>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnmf_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperplexity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msub_sampling\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# perplexity\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NMF' object has no attribute 'perplexity'"
     ]
    }
   ],
   "source": [
    "nmf_model.perplexity(X, sub_sampling=False) # perplexity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3a09059e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41851454570039087\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "import gensim.corpora as corpora\n",
    "\n",
    "def get_Cv(model, df_columnm):\n",
    "  topics = model.components_\n",
    "\n",
    "  n_top_words = 20\n",
    "  texts = [[word for word in doc.split()] for doc in df_columnm]\n",
    "\n",
    "  # create the dictionary\n",
    "  dictionary = corpora.Dictionary(texts)\n",
    "  # Create a gensim dictionary from the word count matrix\n",
    "\n",
    "  # Create a gensim corpus from the word count matrix\n",
    "  corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "  feature_names = [dictionary[i] for i in range(len(dictionary))]\n",
    "\n",
    "  # Get the top words for each topic from the components_ attribute\n",
    "  top_words = []\n",
    "  for topic in topics:\n",
    "      top_words.append([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "\n",
    "  coherence_model = CoherenceModel(topics=top_words, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "  coherence = coherence_model.get_coherence()\n",
    "  return coherence\n",
    "\n",
    "cv = get_Cv(nmf_model, comments_list)\n",
    "print(\"CS:\"cv)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97b184c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'perplexity' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e4782f4a2f96>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mperplexity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msub_sampling\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'perplexity' is not defined"
     ]
    }
   ],
   "source": [
    "perplexity(X, sub_sampling=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fffa9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
